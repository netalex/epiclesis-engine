# vLLM self-host (OpenAI-compatibile)
OPENAI_API_KEY=not-needed
OPENAI_MODEL=meta-llama/llama-3.1-70b-instruct
OPENAI_BASE=http://localhost:8000/v1
